\section{Experimental Approach}



\subsection{Learning Methods}

\edit{write this.  Old quadratot Method section below}

%\section{Method}
\seclabel{method}

% Describe in reasonable detail the algorithm you are using to address
% this problem. A pseudo-code description of the algorithm you are
% using is frequently useful. If it makes sense for your project,
% trace through a concrete example, showing how your algorithm
% processes this example. The example should be complex enough to
% illustrate all of the important aspects of the problem but simple
% enough to be easily understood. If possible, an intuitively
% meaningful example is better than one with meaningless symbols.

We use several parameterized motion models that command motors to
positions based on a sine wave, creating a periodic pattern.  While we
investigated several models, for the bulk of our experiments, we used
a model whose five parameters are: amplitude, wavelength, scale inner
vs outer motors, scale left vs right motors, scale back vs front
motors. Each strategy below attempts to choose the best possible
parameters for this motion model.  

We implemented and tested 8 different learning strategies.  All
strategies except for the HyperNEAT method\cite{clune} were
constrained to pick parameters from within predetermined ranges.

\begin{itemize}

\item \emph{Random}: This method randomly generates parameter vectors
  in the allowable range. This strategy is used only as baseline.

\item \emph{Uniform random hill climbing}: This method begins by
  selecting a single random parameter vector.  Subsequent iterations
  generate a neighbor by randomly choosing one parameter to adjust and
  replacing it with a new value chosen with uniform probability in the
  allowable range for that parameter. The neighbor is evaluated by
  running the robot with the newly chosen parameters. If this neighbor
  results in a longer distance walked than the previous best gait, it
  is saved as the new best gait. The process is then repeated, always
  starting with the best gait.

\item \emph{Gaussian random hill climbing}: This method works
  similarly to Uniform random hill climbing, except neighbors are
  generated by adding random Gaussian noise to the current best gait.
  This results in all parameters being changed at once, but the
  resulting vector is always fairly close to the previous best gait.
  We used independently selected noise in each dimension, scaled such
  that the standard deviation of the noise was 5\% of the range of
  that dimension.

\item \emph{N-dimensional policy gradient descent}: As opposed to the
  previous methods, this method explicitly estimates the gradient for
  the objective function. It does this by first evaluating \emph{t}
  randomly generated parameter vectors near the initial vector, each
  dimension of these vectors being perturbed by either $-\epsilon$,
  $0$, or $\epsilon$. Then, for each dimension, it groups vectors into
  three groups: $-\epsilon$, $0$, and $\epsilon$.  The gradient along
  this dimension is then estimated as the average score for the
  $\epsilon$ group minus the average score for the $-\epsilon$
  group. Finally, the method creates a new vector by changing all
  parameters by a fixed-size step in the direction of the gradient.

\item \emph{Nelder-Mead simplex method}\cite{nm}: The Nelder-Mead
  simplex method creates an initial simplex with 6 vertices. The
  initial parameter vector is stored as the first vertex and the other
  five vertices are created by adding to one dimension at a time one
  tenth of the allowable range for that parameter. It then tests the
  fitness of each vertex and based on these fitnesses, it reflects the
  worst point over the centroid in an attempt to improve it.  However,
  to prevent cycles and becoming stuck in local minima, several other
  rules are used.  In general, the worst vertex is reflected over the
  centroid. If the reflected point is better than the second worst
  point and worse than the best point, then the reflected point
  replaces the worst. If the reflected point is better than the best
  point, the simplex is expanded in the direction of the reflected
  point. The better of the reflected and the expanded point replaces
  the worst point. If the reflected point is worse than the second
  worst point, then the simplex is contracted away from the reflected
  point. If the contracted point is better than the reflected point,
  the contracted point replaces the worst point. If the contracted
  point is worse than the reflected point, the entire simplex is
  shrunk \cite{nm}.

\item \emph{Linear regression}: To initialize, this method chooses and
  evaluates five random parameter vectors. It then fits a linear model
  from parameter vector to fitness. In a loop, the method chooses and
  evaluates a new parameter vector generated by taking a fixed-size
  step in the direction of the gradient for each parameter, and fits a
  new linear model to all vectors evaluated so far, choosing the model
  to minimize the sum of squared errors.

\item \emph{SVM regression}: Similarly to linear regression, this
  model starts with several random vectors, but this time they are
  chosen in a small neighborhood about some initial random vector.
  These vectors (generally 8) are evaluated, and a support vector
  regression model is fit to the observed fitnesses.  To choose the
  next vector for evaluation, we randomly generate some number
  (typically 100) of vectors in the neighborhood of the best observed
  gait, and select for evaluation the vector with the best predicted
  performance.  We suspected that if we always chose the best
  predicted point out of 100, we may end up progressing along a narrow
  subspace, prohibiting learning of the true local fitness function.
  Put another way, we would always choose exploitation of knowledge
  vs. exploration of the space.  To address this concern, we added a
  parameter dubbed \code{bumpBy} that added noise to the final
  selected point before it was evaluated.

  Such a method naturally has many tunable parameters, and we
  endeavored to select these parameters by tuning the method in
  simulation.  To estimate the performance of the algorithm, we ran it
  against a simulation with a known optimum.  The simulated function
  was in the same five dimensional parameter space, and simply
  returned a fitness determined as the height of a Gaussian with a
  random mean.  The width of the Gaussian in each dimension was 20\%
  of the range of each dimension, and the maximum value at the peak
  was 100.  \figref{svm_sim_results} shows the learning results on
  this simulated model using the ultimately selected SVM parameters.
  Interestingly, a non-zero value of \code{bumpBy} resulted in better
  learning than noise free (exploration free) learning.

  Ultimately, however, the version of SVM tuned for simulation still
  did not show competitive performance on the real robot.  We tried
  tuning some parameters on the real robot, but after some amount of
  tuning, the method still exhibited too little exploration and easily
  became stuck in local minima.

\item \emph{Evolutionary Neural Network (HyperNEAT)\cite{clune}}: We 
  put together an interface between HyperNEAT
  -- an implementation of a method for evolving neural networks -- and
  the robot, requiring a slightly modified strategy interface.
  

  % Preliminary HyperNEAT runs were promising and resulted in several
  % interesting gaits.  

  % Unfortunately, the gaits generated by HyperNEAT
  % also tended to stress the robot more than typical gaits had before,
  % and the servos would often overheat and malfunction, requiring
  % restarts.  We think these issues may be addressed by adding a small
  % layer between the HyperNEAT strategy and the robot that disallows
  % quickly shifting commanded positions, and we hope to be able to test
  % these methods further once this filter is in place.

\end{itemize}

\figvarp{svm_sim_results}{.6}{Results for the SVM regression strategy
  in simulation.  This simulation was used to tune the SVM strategy's
  parameters before trying it on the physical robot.  The strategy
  quickly approaches the maximum simulated fitness of 100.}{}



\subsection{Platform details}

\edit{write this.  Old quadratot System Architecture and Implementation section below.}

%\section{System Architecture and Implementation}
\seclabel{implement}

% Describe how you implemented your system and how you structured it. 
% This should give an overview of the system, not a detailed 
% documentation of the code. The documentation of the code is part of 
% the code you hand in. You might want to comment on high-level design 
% decisions that you made. Also explain how you obtained your
% data and any pre-processing you did to it.

The quadruped robot has an on-board computer running Linux. The lower
level drivers are in C and the system is implemented in
Python. Feedback about distance travelled is provided via an infrared
LED mounted on the robot and a Wii remote fixed to the ceiling.

An overview of the code follows.

\begin{itemize}

\item \code{Robot} class: Class wrapper for commanding
  motion of the robot.  The \code{Robot} class takes care of the robot
  initialization, communication with the servos, and timing of the
  runs.  In addition, it prevents the servos from ever being commanded
  to a point outside their normal range (0 - 1023) as well as beyond
  points where limbs would collide with parts of the robot body.  The
  main class function, \code{run}, accepts a motion model (any
  function that takes a time argument and outputs a 9 dimensional
  position) and will run the robot using this motion model, including,
  if desired, smooth interpolation over time for the beginning and end
  of the run.

\item \code{RunManager} class: Deals with all the details of running
  the robot, including running the robot multiple times, tracking
  distance walked via a \code{WiiTrackClient} member object, and
  writing results to the log file. Also includes the
  \code{explore\_dimensions} method to generate plots by varying each
  parameter independently.

\item \code{Strategy} class: The user has a choice between eight
  different learning strategies: Random search, uniform random hill
  climbing, Gaussian random hill climbing, N-dimensional policy
  gradient descent, Nelder-Mead simplex, linear regression/prediction,
  SVM regression/prediction, and HyperNEAT evolution.  Each strategy
  must derive from the base \code{Strategy} class and must implement
  two methods: \code{getNext}, for getting the next parameter vector
  to try, and \code{updateResults}, for communicating results of a run
  back to the strategy.

\item \code{MotionModel} class: We implemented several motion models,
  the main being the \code{SineModel5} class.  All motion models take
  as input a parameter vector and produce as output a motion model,
  which is simply a function mapping from time to nine motor
  positions.  The \code{SineModel5} model commands positions based on
  a sine wave, creating a periodic pattern. The parameters are:
  amplitude, wavelength, a multiplier for the inner vs outer motors,
  multiplier for left vs right motors, and multiplier for back vs
  front motors.  Other similar models were tested, including a seven
  parameter model which allowed sine waves shifted in time, but these
  were not used as extensively in our experiments as
  \code{SineModel5}.

\item \code{WiiTrackClient} and \code{WiiTrackServer} classes and
  hardware: A Wii remote tracks the location of the robot through an
  infrared LED mounted on top of the robot. A \code{WiiTrackServer} is
  run on the robot and continuously tracks its position using the
  CWiid library\cite{cwiid} to interface with the remote via
  bluetooth.  The \code{RunManager} then makes a
  \code{WiiTrackClient}, which connects via socket to the tracking
  server and requests position updates periodically.
  \code{RunManager} currently gets the robot's position at the
  beginning of each run and then again at the end and uses this to
  calculate the net change in position.

\end{itemize}



\subsection{Fitness evaluation details}

\edit{write this.  Old quadratot Experimental Evaluation section below.}

%\section{Experimental Evaluation}

%\subsection{Methodology}
% What are the criteria you are using to evaluate your method? What
% specific hypotheses does your experiment test? Describe the 
% experimental methodology that you used. What are the dependent and 
% independent variables? For projects in machine learning, what is 
% the training/test data that was used, and why is it realistic or
% interesting? Exactly what performance data did you collect and how 
% are you presenting and analyzing it? Comparisons to competing methods 
% that address the same problem or to variations of your own algorithm 
% are particularly useful.

The metric for evaluation of the designed gait is speed. We stop each 
run after plateauing results (no improvement for one third of the 
policies seen so far). The standard length of a run designates that it
should be stopped after there is no improvement for one half of the policies
seen so far, but since all runs took place on the actual robot, without use
of a simulator, certain time limitations were imposed on the learning process.

We controlled our experiments from a computer that was connected via a
wireless ethernet to the robot. The robot collected data about
distance walked automatically on its own. If it walked outside of the
Wii remote's viewable area, it informed the user, so the only human
intervention required during an experiment was to move the robot back
inside the viewable area and to resume the run, which did not
interrupt the learning process or result in the loss of data.

We evaluated the efficacy of a set of parameters by sending these
parameters to the robot and instructing it to walk for a certain
length of time. The robot always began from the same position and
returned to the starting position at the end of the run in order to
measure true displacement without giving credit for ending in a leaned
position. More efficient parameters resulted in a faster gait, which
translated into a longer distance walked and a better score. After completing
an evaluation, the robot sent the resulting distance walked back to the
host computer and prepared itself for a new set of parameters to evaluate.

Each algorithm was run on 3 different initial parameter vectors on the
physical robot. We decided to evaluate all methods starting at the
same three vector in order to allow for the fair comparison of each
algorithm.  We evaluate each method based on the amount of improvement
seen from the initial parameter vectors, and on the fastest speeds
achieved during runs.

The resulting gaits from our algorithms quickly outperformed the original
hand-coded walk designed for this robot. The fastest walk, for example, was
4 times faster.
