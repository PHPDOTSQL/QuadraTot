\section{Results and Discussion}
\seclabel{results}

% Outline:
% - exploration of parameter space
% - parameterized optimization results, discussion
% - HyperNEAT results, discussion



\subsection{Exploration of Parameterized Gait Space}

%\edit{Jeff: proofread}

Before optimizing the chosen family of
parameterized gaits (\secref{motionModel}) with learning methods, we performed an experiment to explore the five dimensions of the parameter space. Specifically, we first selected a random parameter vector that resulted
in motion, but not an exceptional gait. In five different experiments, we then varied each parameter
individually and measured performance.
Each measurement was repeated to get a rough estimate
of the measurement noise at each point.  The results
of this exploration (Figures \ref{fig:explore_dim_1} through
\ref{fig:explore_dim_5}) reveal that some dimensions
are smoother than others and that the measurement noise is variable and can be quite high. 

%\acmFig{explore_dim_1}{1}{Fitness mean and standard deviation
%  vs. dimension 1.  The circle is a common point in
%  \figref{explore_dim_1} through \figref{explore_dim_5}}
%\acmFig{explore_dim_2}{1}{Fitness mean and standard deviation
%  vs. dimension 2.  The circle is a common point in
%  \figref{explore_dim_1} through \figref{explore_dim_5}}
%\acmFig{explore_dim_3}{1}{Fitness mean and standard deviation
%  vs. dimension 3.  The circle is a common point in
%  \figref{explore_dim_1} through \figref{explore_dim_5}}
%\acmFig{explore_dim_4}{1}{Fitness mean and standard deviation
%  vs. dimension 4.  The circle is a common point in
%  \figref{explore_dim_1} through \figref{explore_dim_5}}
%\acmFig{explore_dim_5}{1}{Fitness mean and standard deviation
%  vs. dimension 5.  The circle is a common point in
%  \figref{explore_dim_1} through \figref{explore_dim_5}}

\acmFiggggg{explore_dim_1}{explore_dim_2}{explore_dim_3}{explore_dim_4}{explore_dim_5}{1}{.5}{Fitness
  mean and standard deviation vs. dimension 5.  The circle is a common
  point in \figref{explore_dim_1} through \figref{explore_dim_5}}



\subsection{Maximizing Strategies}


The maximizing strategies implemented include uniform random hill
climbing, Gaussian random hill climbing, policy gradient descent, and
Nelder-Mead simplex. As a group, these strategies produced results
similar to gaits randomly-generated with the SineModel5 model. None
of these strategies consistently outperformed the others in the three
trials; A different strategy generated the best gait in each
trial. Uniform random hill climbing produced the best gait (11.37 body
lengths/minute) in the first trial, with the next best performing
strategy (Nelder-Mead simplex) resulting in a gait of 8.51 body
lengths/minute. The best gait in the second trial was actually
generated randomly (17.26 body-lengths/minute). Gaussian random hill
climbing, policy gradient descent, and Nelder-Mead simplex all
produced similar best gaits in the second trial, each around 14 body
lengths/minute. In the third trial, Nelder-Mead simplex and Gaussian
random hill climbing significantly outperformed the other maximizing
strategies, resulting in gaits of 14.83 and 13.40 body lengths/minute
respectively. Overall, Nelder-Mead simplex performed the best,
producing an average best gait of 12.32 body lengths/minute. Gaussian
random hill climbing followed, with an average best gait of 10.03 body
lengths/minute.



\subsection{Predictive Strategies}

The predictive strategies used were linear regression and support
vector regression. In the first trial, linear regression produced a
gait (27.58 body lengths/minute) that was over three times faster than
the best gait produced by a maximizing strategy (uniform random hill
climbing -- 11.37 body lengths/minute). The average of the best gait
for the three trials of linear regression was 14.01 body
lengths/minute, which was better than the average best gait for the
best performing maximizing strategy (Nelder-Mead simplex -- 12.32 body
lengths/minute).

%As mentioned above, the SVM strategy involved many tunable
%parameters. The version of SVM tuned for simulation did not show
%competitive performance on the real robot. We tried tuning some
%parameters on the real robot, but after some amount of tuning, the
%method still exhibited too little exploration and easily became stuck
%in local minima.
%
%\edit{say something about tuning SVM and the sim figure}
%
%\acmFig{svm_sim_results}{1}{Results for the SVM regression strategy
%  in simulation.  This simulation was used to tune the SVM strategy's
%  parameters before trying it on the physical robot.  The strategy
%  quickly approaches the maximum simulated fitness of 100.}



\subsection{Evolved Neural Network Strategy}

The evolved neural network strategy used was HyperNEAT. HyperNEAT
produced the fastest gaits by far. Linear regression produced a gait
in the first trial (27.58 body lengths/minute) that was on par with
the best gaits generated by HyperNEAT, but no other maximizing or
predictive strategy produced gaits close to those of HyperNEAT. Linear
regression was the best performing maximizing or predictive strategy,
but it resulted in an average best gait of only 14.01 body
lengths/minute. HyperNEAT, on the other hand, resulted in an average
best gait of 29.26 body lengths/minute. One issue encountered with
HyperNEAT was that it generated gaits that were rougher on the robot
than gaits generated by the other strategies. The gaits sometimes
caused the motor servos to overheat, which caused the motor to behave
differently than expected. Since an overheated motor produces a
different walk that expected, a test was performed after each run to
make sure all motors were working correctly. If a motor failed, the
distance walked would be halved to penalize walks that were harmful to
the robot.

\edit{take this out?}

We have done complete runs of 3 different initial parameter vectors
for random search, uniform random hill climbing, Gaussian random hill
climbing, policy gradient descent, Nelder-Mead simplex, and linear
regression.  We also evaluated the SVM regression and HyperNEAT
methods, but these methods were more experimental, and thus we do not
yet have the same volume of data for these runs.  We developed several
gaits that were about 4 times faster than the original hand-coded
gait.  Results are shown in \tabref{results_table}.



\begin{table*}
\begin{center}
\begin{tabular}{|r|c|c|c||c|}
\hline
                                         & A       & B      & C      &  Average \\
\hline                                                               
\hline                                                               
Previous hand-coded gait                 & --      & --     & --     &  5.16 \\
\hline                                                                 
Random search                            & 6.04    & 17.26  & 4.90   &  9.40 \\
\hline                                                                 
Uniform Random Hill Climbing             & 11.37   & 9.44   & 2.69   &  7.83 \\
\hline                                                                 
Gaussian Random Hill Climbing            & 3.10    & 13.59  & 13.40  &  10.03 \\
\hline                                                                 
Policy Gradient Descent                  & 0.68    & 14.69  & 3.60   &  6.32 \\
\hline                                                                 
Nelder-Mead simplex                      & 8.51    & 13.62  & 14.83  &  12.32 \\
\hline                                                                 
Linear Regression                        & 27.58   & 12.51  & 1.95   &  14.01 \\
\hline                                                                
Evolutionary Neural Network (HyperNEAT)  & 24.27     & 36.44    & 27.07   & 29.26  \\
\hline
\end{tabular}
\caption{The best gaits found for each starting vector and algorithm,
  in body lengths per minute.}
\tablabel{results_table}
\end{center}
\end{table*}



\begin{itemize}

\item For vector A, shown in \figref{vectorA}, linear regression
  worked significantly better than the other algorithms, resulting in
  a gait (27.58 body lengths/minute) that walked over twice as fast as
  the next best gait -- uniform random hill climbing at 11.37 body
  lengths/minute -- and 5.3 times better than the previous hand-coded
  gait.

\item Vector B, depicted in \figref{vectorB}, resulted in similarly
  performing gaits with all the algorithms. The random method got
  lucky and produced the best gait (17.26 body lengths/minute) and
  uniform random hill climbing produced the worst (9.44 body
  lengths/minute). The remaining algorithms each produced a gait
  around 13 body lengths/minute.

\item For vector C, shown in \figref{vectorC}, simplex and Gaussian
  random hill climbing each produced a gait that substantially
  outperformed the other algorithms. Simplex resulted in a gait of
  nearly 15 body lengths/minute and Gaussian random hill climbing
  produced a gait of just over 13 body lengths/minute, whereas the
  other algorithms returned gaits of less than 5 body lengths/minute.

\end{itemize}

%\acmFig{vectorA}{1}{Results for runs beginning with vector A.
%  Linear regression worked significantly better than the other
%  algorithms, resulting in a gait (27.58 body lengths/minute) that
%  walked over twice as fast as the next best gait -- uniform random
%  hill climbing at 11.37 body lengths/minute -- and 5.3 times better
%  than the previous hand-coded gait.}
%
%\acmFig{vectorB}{1}{Results for run starting with vector B.  All
%  algorithms performed similarly.  The random method actually got
%  lucky this time and produced the best gait (17.26 body
%  lengths/minute) and uniform random hill climbing produced the worst
%  (9.44 body lengths/minute). The remaining algorithms each produced a
%  gait around 13 body lengths/minute.}
%
%\acmFig{vectorC}{1}{Results for runs starting with vector C.
%  Simplex and Gaussian random hill climbing each produced a gait that
%  substantially outperformed the other algorithms, with around 15 body
%  lengths/minute and 13 body lengths/minute, respectively, whereas the
%  other algorithms returned gaits of less than 5 body
%  lengths/minute.}



\acmFigDouble{std_error}{.6}{Average results ($\pm $ SEM) for each of the parametrized learning methods.  Linear regression performed the best,
  followed by Nelder-Mead simplex. Gaussian random hill
climbing performed about as well as random search, but may have surpassed random
with additional iterations. Uniform random hill
climbing and policy gradient descent performed similarly to each other
and underperformed random search.}



\subsection{Discussion}

% Is your hypothesis supported? What conclusions do the results support
% about the strengths and weaknesses of your method compared to other 
% methods? How can the results be explained in terms of the underlying 
% properties of the algorithm and/or the data.

Because only three trials were tested with each algorithm and no
algorithm consistently outperformed the others, there is a large
standard error for each algorithm, as show in \figref{std_error}. For
this reason, it is unclear if any algorithm is superior to another in
this application. More trials with each algorithm would be necessary
to reach a definitive ranking of the performance of the algorithms.

However, each algorithm discovered at least one gait of over 10 body
lengths/minute, including random. For this reason, we speculate that
the motion model is at least as critical as the learning algorithm
used.

\acmFig{neat_110115_211410_00000_002_filt}{1}{Caption here...???}
\acmFig{neat_110115_211410_00000_002_filt_zoom}{1}{Caption here...???}
