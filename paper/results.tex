\section{Results and Discussion}
\seclabel{results}

% Outline:
% - exploration of parameter space
% - parameterized optimization results, discussion
% - HyperNEAT results, discussion



\subsection{Exploration of Parameterized Gait Space}

\edit{Jeff: proofread again}

Before optimizing the chosen family of parameterized gaits
(\secref{motionModel}) with learning methods, we performed an
experiment to explore the five dimensions of the SineModel5 parameter
space. Specifically, we selected a random parameter vector that
resulted in some motion, but not an exceptional gait. We then varied
each of the five parameters individually and measured performance,
repeating each measurement twice to get a rough estimate of the
measurement noise at each point.  The results of this exploration,
shown in \figref{explore_dim_1}, reveal that some dimensions ($\amp$,
$\tau$, $m_F$) are fairly smooth and exhibit global structure across
the allowable parameter range, while others ($m_O$, $m_R$) exhibit
more complex behavior.  In addition, it gives a rough indication that
measurement noise is often significant and is more likely to be large
for larger measurements.  Of course, this is only a slice in each
dimension through a single point, and slices through a different point
would produce different behavior.  The common point at the
intersection of all slices is shown as a red triangle in
each plot of \figref{explore_dim_1}.


%\acmFig{explore_dim_1}{1}{Fitness mean and standard deviation
%  vs. dimension 1.  The circle is a common point in
%  \figref{explore_dim_1} through \figref{explore_dim_5}}
%\acmFig{explore_dim_2}{1}{Fitness mean and standard deviation
%  vs. dimension 2.  The circle is a common point in
%  \figref{explore_dim_1} through \figref{explore_dim_5}}
%\acmFig{explore_dim_3}{1}{Fitness mean and standard deviation
%  vs. dimension 3.  The circle is a common point in
%  \figref{explore_dim_1} through \figref{explore_dim_5}}
%\acmFig{explore_dim_4}{1}{Fitness mean and standard deviation
%  vs. dimension 4.  The circle is a common point in
%  \figref{explore_dim_1} through \figref{explore_dim_5}}
%\acmFig{explore_dim_5}{1}{Fitness mean and standard deviation
%  vs. dimension 5.  The circle is a common point in
%  \figref{explore_dim_1} through \figref{explore_dim_5}}

\acmFiggggg{explore_dim_1}{explore_dim_2}{explore_dim_3}{explore_dim_4}{explore_dim_5}{1}{.53}{Fitness
  mean and standard deviation when each parameter dimension is varied
  independently.  The red triangle in each plot represents the same point in the 5-dimensional parameter space.}



\subsection{Learning Methods for Parameterized Gaits}

% Outline
% - beat hand gait
% - no learning strategy outperformed another by that much
% - real world noise yay

The results for the parameterized gaits are shown in
\figref{std_error} and \tabref{results}.  As a group, these strategies
produced results not significantly better than the randomly-generated
gaits, however, all methods managed to explore the space enough to
significantly improve on the previous hand coded gait in at least one
of the three runs.  No single strategy consistently outperformed the
others: for the first trial Linear Regression produced the fastest
gait at 27.58 body lengths per minute, for the second a random gait
actually won with 17.26 body lengths / minute, and for the third trial
the Nelder-Mead simplex method attained the fastest gait at 14.83 body
lengths / minute.



% octave:15> fit = [6.04 17.26 4.90;  11.37 9.44 2.69;  3.10 13.59 13.40;  0.68 14.69 3.60;  8.51 13.62 14.83;  27.58 12.51 1.95;  24.27  36.44  27.07];
% octave:16> mean(fit,2)
% ans =
% 
%     9.4000
%     7.8333
%    10.0300
%     6.3233
%    12.3200
%    14.0133
%    29.2600
% 
% octave:17> std(fit,0,2)
% ans =
% 
%     6.8308
%     4.5576
%     6.0023
%     7.3914
%     3.3546
%    12.8810
%     6.3737


%%%%%% OLD TABLE
% \begin{table*}
% \begin{center}
% \begin{tabular}{|r|c|c|c||c|}
% \hline
%                                          & A       & B      & C      &  Average \\
% \hline                                                               
% \hline                                                               
% Previous hand-coded gait                 & --      & --     & --     &  5.16 \\
% \hline                                                                 
% Random search                            & 6.04    & 17.26  & 4.90   &  9.40 \\
% \hline                                                                 
% Uniform Random Hill Climbing             & 11.37   & 9.44   & 2.69   &  7.83 \\
% \hline                                                                 
% Gaussian Random Hill Climbing            & 3.10    & 13.59  & 13.40  &  10.03 \\
% \hline                                                                 
% Policy Gradient Descent                  & 0.68    & 14.69  & 3.60   &  6.32 \\
% \hline                                                                 
% Nelder-Mead simplex                      & 8.51    & 13.62  & 14.83  &  12.32 \\
% \hline                                                                 
% Linear Regression                        & 27.58   & 12.51  & 1.95   &  14.01 \\
% \hline                                                                
% Evolutionary Neural Network (HyperNEAT)  & 24.27     & 36.44    & 27.07   & 29.26  \\
% \hline
% \end{tabular}
% \caption{The best gaits found for each starting vector and algorithm,
%   in body lengths per minute.}
% \tablabel{results}
% \end{center}
% \end{table*}

%%%%%%% NEW TABLE
\begin{table}
\begin{center}
\begin{tabular}{|r|c|c|c||c|}
\hline
                                         & Average & Std. Dev. \\
\hline                                    
\hline                                    
Previous hand-coded gait                 & 5.16   &   --     \\
\hline
Random search                            & 9.40   &   6.83   \\
\hline
Uniform Random Hill Climbing             & 7.83   &   4.56   \\
\hline
Gaussian Random Hill Climbing            & 10.03  &   6.00   \\
\hline
Policy Gradient Descent                  & 6.32   &   7.39   \\
\hline
Nelder-Mead simplex                      & 12.32  &   3.35   \\
\hline
Linear Regression                        & 14.01  &  12.88   \\
\hline
Evolved Neural Network              &        &          \\
(HyperNEAT)                              & 29.26  &   6.37   \\
\hline
\end{tabular}
\caption{The best gaits found for each starting vector and algorithm,
  in body lengths per minute.}
\tablabel{results}
\end{center}
\end{table}



\acmFig{std_error}{1}{Average results ($\pm $ standard error) for each
  of the parameterized learning methods.  Linear regression found the
  fastest overall gait and had the highest average, followed by
  Nelder-Mead simplex. Many methods were beaten by the simple random
  strategy.}




\subsection{Evolved Neural Network Strategy}

The evolved neural network strategy used was HyperNEAT. HyperNEAT
produced the fastest gaits by far. Linear regression produced a gait
in the first trial (27.58 body lengths/minute) that was on par with
the best gaits generated by HyperNEAT, but no other maximizing or
predictive strategy produced gaits close to those of HyperNEAT. Linear
regression was the best performing maximizing or predictive strategy,
but it resulted in an average best gait of only 14.01 body
lengths/minute. HyperNEAT, on the other hand, resulted in an average
best gait of 29.26 body lengths/minute. One issue encountered with
HyperNEAT was that it generated gaits that were rougher on the robot
than gaits generated by the other strategies. The gaits sometimes
caused the motor servos to overheat, which caused the motor to behave
differently than expected. Since an overheated motor produces a
different walk that expected, a test was performed after each run to
make sure all motors were working correctly. If a motor failed, the
distance walked would be halved to penalize walks that were harmful to
the robot.

\edit{take this out?}

We have done complete runs of 3 different initial parameter vectors
for random search, uniform random hill climbing, Gaussian random hill
climbing, policy gradient descent, Nelder-Mead simplex, and linear
regression.  We also evaluated the SVM regression and HyperNEAT
methods, but these methods were more experimental, and thus we do not
yet have the same volume of data for these runs.  We developed several
gaits that were about 4 times faster than the original hand-coded
gait.  Results are shown in \tabref{results}.




\subsection{Discussion}

% Is your hypothesis supported? What conclusions do the results support
% about the strengths and weaknesses of your method compared to other 
% methods? How can the results be explained in terms of the underlying 
% properties of the algorithm and/or the data.

Because only three trials were tested with each algorithm and no
algorithm consistently outperformed the others, there is a large
standard error for each algorithm, as show in \figref{std_error}. For
this reason, it is unclear if any algorithm is superior to another in
this application. More trials with each algorithm would be necessary
to reach a definitive ranking of the performance of the algorithms.

However, each algorithm discovered at least one gait of over 10 body
lengths/minute, including random. For this reason, we speculate that
the motion model is at least as critical as the learning algorithm
used.

\acmFig{neat_110115_211410_00000_002_filt}{1}{Caption here...???}
\acmFig{neat_110115_211410_00000_002_filt_zoom}{1}{Caption here...???}
