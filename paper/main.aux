\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\citation{chestnutt2006footstep}
\citation{raibert2008bigdog}
\citation{chestnutt2006footstep}
\citation{raibert2008bigdog}
\citation{hornby2005autonomous}
\citation{valsalam2008modular}
\citation{stanley2009hypercube}
\citation{clune2009evolving}
\citation{clune2011performance}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction and Background}{\thepage }{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The quadruped robot. The translucent parts were created with 3D-printing technology.}}{\thepage }{figure.1}}
\newlabel{fig:robot_close.jpg}{{1}{\thepage }{The quadruped robot. The translucent parts were created with 3D-printing technology}{figure.1}{}}
\citation{clune2009evolving}
\citation{clune2011performance}
\citation{valsalam2008modular}
\citation{clune2009evolving}
\citation{clune2011performance}
\citation{kohl}
\citation{chernova2005evolutionary}
\citation{hornby2005autonomous}
\citation{zykov}
\citation{clune2009evolving}
\citation{clune2011performance}
\citation{clune2009hybrid}
\citation{clune2009sensitivity}
\citation{tellez2006evolving}
\citation{valsalam2008modular}
\citation{hornby2005autonomous}
\citation{clune2009evolving}
\citation{clune2011performance}
\citation{clune2009hybrid}
\citation{clune2009sensitivity}
\citation{valsalam2008modular}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Related Work}{\thepage }{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Outline of Sections}{\thepage }{subsection.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem definition}{\thepage }{section.2}}
\newlabel{sec:problemDefinition}{{2}{\thepage }{Problem definition\relax }{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces A figure of the robot from a top-down perspective, with servos labeled}}{\thepage }{figure.2}}
\newlabel{fig:topdown.png}{{2}{\thepage }{A figure of the robot from a top-down perspective, with servos labeled\relax }{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experimental Setup}{\thepage }{section.3}}
\newlabel{sec:experimentalSetup}{{3}{\thepage }{Experimental Setup\relax }{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Platform details}{\thepage }{subsection.3.1}}
\newlabel{sec:platformDetails}{{3.1}{\thepage }{Platform details\relax }{subsection.3.1}{}}
\citation{quadraWeb}
\citation{pydynamixel}
\citation{cwiid}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A Nintendo Wii remote tracks the location of the robot, providing feedback about distance traveled, in pixels, through an infrared LED mounted on top of the robot.}}{\thepage }{figure.3}}
\newlabel{fig:wiiMote_crop.jpg}{{3}{\thepage }{A Nintendo Wii remote tracks the location of the robot, providing feedback about distance traveled, in pixels, through an infrared LED mounted on top of the robot}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Fitness Evaluation Details}{\thepage }{subsection.3.2}}
\newlabel{sec:fitnessEvaluation}{{3.2}{\thepage }{Fitness Evaluation Details\relax }{subsection.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Gait Generation and Learning}{\thepage }{section.4}}
\newlabel{sec:gaitGenLearn}{{4}{\thepage }{Gait Generation and Learning\relax }{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Parametrized Motion Models}{\thepage }{subsection.4.1}}
\newlabel{sec:motionModel}{{4.1}{\thepage }{Parametrized Motion Models\relax }{subsection.4.1}{}}
\citation{kohl}
\citation{nm}
\citation{nm}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The parameters used for the \emph  {SineModel5} motion model.}}{\thepage }{table.1}}
\newlabel{tab:parameters}{{1}{\thepage }{The parameters used for the \emph {SineModel5} motion model}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Learning Methods for Parametrized Motion Models}{\thepage }{subsection.4.2}}
\newlabel{sec:learningMethods}{{4.2}{\thepage }{Learning Methods for Parametrized Motion Models\relax }{subsection.4.2}{}}
\citation{stanley2009hypercube}
\citation{stanley2007compositional}
\citation{stanley2009hypercube}
\citation{stanley2009hypercube}
\citation{stanley2007compositional}
\citation{stanley2009hypercube}
\citation{clune2009sensitivity}
\citation{clune2011performance}
\citation{clune2009evolving}
\citation{clune2011performance}
\citation{stanley2002evolving}
\citation{stanley2002evolving}
\citation{stanley2002evolving}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}HyperNEAT Motion Model}{\thepage }{subsection.4.3}}
\newlabel{sec:hyperNeatMethod}{{4.3}{\thepage }{HyperNEAT Motion Model\relax }{subsection.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces HyperNEAT Produces ANNs from CPPNs. ANN weights are specified as a function of the geometric coordinates of the source node and the target node for each connection. The coordinates of these nodes and a constant bias are iteratively passed to the CPPN to determine each connection weight. The CPPN has two output values, which specify the weights for each connection layer as shown.}}{\thepage }{figure.4}}
\newlabel{fig:hyperneatExplanation.png}{{4}{\thepage }{HyperNEAT Produces ANNs from CPPNs. ANN weights are specified as a function of the geometric coordinates of the source node and the target node for each connection. The coordinates of these nodes and a constant bias are iteratively passed to the CPPN to determine each connection weight. The CPPN has two output values, which specify the weights for each connection layer as shown}{figure.4}{}}
\citation{clune2011performance}
\citation{clune2009evolving}
\citation{clune2011performance}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results and Discussion}{\thepage }{section.5}}
\newlabel{sec:results}{{5}{\thepage }{Results and Discussion\relax }{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Exploration of Parameter Space}{\thepage }{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Maximizing Strategies}{\thepage }{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces ANN Configuration for HyperNEAT Runs. The first two columns of each row of the input layer receive information about a single leg (the current angle of its two joints). The final column provides a sine and cosine wave to enable periodic movements and the angle of the center joint. Evolution determines the function of the hidden-layer nodes. The nodes in the output layer specify new joint angles for each respective joint. The unlabeled node in the input and output layer is ignored.}}{\thepage }{figure.5}}
\newlabel{fig:SpiderANN.jpg}{{5}{\thepage }{ANN Configuration for HyperNEAT Runs. The first two columns of each row of the input layer receive information about a single leg (the current angle of its two joints). The final column provides a sine and cosine wave to enable periodic movements and the angle of the center joint. Evolution determines the function of the hidden-layer nodes. The nodes in the output layer specify new joint angles for each respective joint. The unlabeled node in the input and output layer is ignored}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Fitness mean and standard deviation vs. dimension 1. The circle is a common point in Figure\nobreakspace  {}\ref  {fig:explore_dim_1} through Figure\nobreakspace  {}\ref  {fig:explore_dim_5}}}{\thepage }{figure.6}}
\newlabel{fig:explore_dim_1}{{6}{\thepage }{Fitness mean and standard deviation vs. dimension 1. The circle is a common point in \figref {explore_dim_1} through \figref {explore_dim_5}\relax }{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Fitness mean and standard deviation vs. dimension 2. The circle is a common point in Figure\nobreakspace  {}\ref  {fig:explore_dim_1} through Figure\nobreakspace  {}\ref  {fig:explore_dim_5}}}{\thepage }{figure.7}}
\newlabel{fig:explore_dim_2}{{7}{\thepage }{Fitness mean and standard deviation vs. dimension 2. The circle is a common point in \figref {explore_dim_1} through \figref {explore_dim_5}\relax }{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Fitness mean and standard deviation vs. dimension 3. The circle is a common point in Figure\nobreakspace  {}\ref  {fig:explore_dim_1} through Figure\nobreakspace  {}\ref  {fig:explore_dim_5}}}{\thepage }{figure.8}}
\newlabel{fig:explore_dim_3}{{8}{\thepage }{Fitness mean and standard deviation vs. dimension 3. The circle is a common point in \figref {explore_dim_1} through \figref {explore_dim_5}\relax }{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Fitness mean and standard deviation vs. dimension 4. The circle is a common point in Figure\nobreakspace  {}\ref  {fig:explore_dim_1} through Figure\nobreakspace  {}\ref  {fig:explore_dim_5}}}{\thepage }{figure.9}}
\newlabel{fig:explore_dim_4}{{9}{\thepage }{Fitness mean and standard deviation vs. dimension 4. The circle is a common point in \figref {explore_dim_1} through \figref {explore_dim_5}\relax }{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Fitness mean and standard deviation vs. dimension 5. The circle is a common point in Figure\nobreakspace  {}\ref  {fig:explore_dim_1} through Figure\nobreakspace  {}\ref  {fig:explore_dim_5}}}{\thepage }{figure.10}}
\newlabel{fig:explore_dim_5}{{10}{\thepage }{Fitness mean and standard deviation vs. dimension 5. The circle is a common point in \figref {explore_dim_1} through \figref {explore_dim_5}\relax }{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Results for the SVM regression strategy in simulation. This simulation was used to tune the SVM strategy's parameters before trying it on the physical robot. The strategy quickly approaches the maximum simulated fitness of 100.}}{\thepage }{figure.11}}
\newlabel{fig:svm_sim_results}{{11}{\thepage }{Results for the SVM regression strategy in simulation. This simulation was used to tune the SVM strategy's parameters before trying it on the physical robot. The strategy quickly approaches the maximum simulated fitness of 100}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Predictive Strategies}{\thepage }{subsection.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Evolved Neural Network Strategy}{\thepage }{subsection.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Discussion}{\thepage }{subsection.5.5}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The best gaits found for each starting vector and algorithm, in body lengths per minute.}}{\thepage }{table.2}}
\newlabel{tab:results_table}{{2}{\thepage }{The best gaits found for each starting vector and algorithm, in body lengths per minute}{table.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Average results for each method starting with parameter vectors A, B, and C. Error bars are plotted showing the standard error. Linear regression outperformed other methods, followed by simplex. Gaussian random hill climbing performed about as well as random, but it is unclear whether Gaussian would continue to improve and become much better than random search if allowed to run for more iterations. Uniform random hill climbing and policy gradient descent performed similarly to each other on average, but differed greatly on individual runs.}}{\thepage }{figure.15}}
\newlabel{fig:std_error}{{15}{\thepage }{Average results for each method starting with parameter vectors A, B, and C. Error bars are plotted showing the standard error. Linear regression outperformed other methods, followed by simplex. Gaussian random hill climbing performed about as well as random, but it is unclear whether Gaussian would continue to improve and become much better than random search if allowed to run for more iterations. Uniform random hill climbing and policy gradient descent performed similarly to each other on average, but differed greatly on individual runs}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Results for runs beginning with vector A. Linear regression worked significantly better than the other algorithms, resulting in a gait (27.58 body lengths/minute) that walked over twice as fast as the next best gait -- uniform random hill climbing at 11.37 body lengths/minute -- and 5.3 times better than the previous hand-coded gait.}}{\thepage }{figure.12}}
\newlabel{fig:vectorA}{{12}{\thepage }{Results for runs beginning with vector A. Linear regression worked significantly better than the other algorithms, resulting in a gait (27.58 body lengths/minute) that walked over twice as fast as the next best gait -- uniform random hill climbing at 11.37 body lengths/minute -- and 5.3 times better than the previous hand-coded gait}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Results for run starting with vector B. All algorithms performed similarly. The random method actually got lucky this time and produced the best gait (17.26 body lengths/minute) and uniform random hill climbing produced the worst (9.44 body lengths/minute). The remaining algorithms each produced a gait around 13 body lengths/minute.}}{\thepage }{figure.13}}
\newlabel{fig:vectorB}{{13}{\thepage }{Results for run starting with vector B. All algorithms performed similarly. The random method actually got lucky this time and produced the best gait (17.26 body lengths/minute) and uniform random hill climbing produced the worst (9.44 body lengths/minute). The remaining algorithms each produced a gait around 13 body lengths/minute}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Results for runs starting with vector C. Simplex and Gaussian random hill climbing each produced a gait that substantially outperformed the other algorithms, with around 15 body lengths/minute and 13 body lengths/minute, respectively, whereas the other algorithms returned gaits of less than 5 body lengths/minute.}}{\thepage }{figure.14}}
\newlabel{fig:vectorC}{{14}{\thepage }{Results for runs starting with vector C. Simplex and Gaussian random hill climbing each produced a gait that substantially outperformed the other algorithms, with around 15 body lengths/minute and 13 body lengths/minute, respectively, whereas the other algorithms returned gaits of less than 5 body lengths/minute}{figure.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion and Future Work}{\thepage }{section.6}}
\newlabel{sec:conclusion}{{6}{\thepage }{Conclusion and Future Work\relax }{section.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Caption here...???}}{\thepage }{figure.16}}
\newlabel{fig:neat_110115_211410_00000_002_filt}{{16}{\thepage }{Caption here...???\relax }{figure.16}{}}
\bibstyle{abbrv}
\bibdata{references}
\bibcite{chernova2005evolutionary}{1}
\bibcite{chestnutt2006footstep}{2}
\bibcite{clune2009evolving}{3}
\bibcite{clune2009hybrid}{4}
\bibcite{clune2009sensitivity}{5}
\bibcite{clune2011performance}{6}
\bibcite{pydynamixel}{7}
\bibcite{hornby2005autonomous}{8}
\bibcite{kohl}{9}
\bibcite{raibert2008bigdog}{10}
\bibcite{nm}{11}
\bibcite{cwiid}{12}
\bibcite{stanley2007compositional}{13}
\bibcite{stanley2009hypercube}{14}
\bibcite{stanley2002evolving}{15}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Caption here...???}}{\thepage }{figure.17}}
\newlabel{fig:neat_110115_211410_00000_002_filt_zoom}{{17}{\thepage }{Caption here...???\relax }{figure.17}{}}
\newlabel{sec:futureWork}{{6}{\thepage }{Conclusion and Future Work\relax }{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Acknowledgments}{\thepage }{section.7}}
\@writefile{toc}{\contentsline {section}{\numberline {8}References}{\thepage }{section.8}}
\bibcite{tellez2006evolving}{16}
\bibcite{valsalam2008modular}{17}
\bibcite{zykov}{18}
