\subsection{Parametrized Motion Models}
\seclabel{motionModel}

We have chosen to implement two classes of algorithms to automatically create the motion-generating function $g(t)$ (described in
\secref{problemDefinition}).  The first method uses a family of
parametrized gaits, described in this section and the next. The
second method evolves a non-parametric gait controlled by neural networks, and is detailed in
\secref{hyperNeatMethod}.

By a \emph{parametrized gait}, we mean a gait produced by a
parametrized function $g(t; \vec{\theta})$. Fixing the parameter
$\vec{\theta}$ yields a deterministic motion function over time.  We
tried several parametrizations on the robot and, upon obtaining
reasonable early success, settled on one particular parametrization, which we call  \emph{SineModel5}. Its root pattern is a sine wave and it has five parameters (\tabref{params}).

%\newcommand{\amp}{\ensuremath{\mathrm{amp}}}
\newcommand{\amp}{\ensuremath{\alpha}}

\begin{table}[h!]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Parameter    & Description               & Range \\
\hline
\hline
\amp         & Amplitude                 & [0, 400] \\
\hline
$\tau$       & Period                    & [.5, 8] \\
\hline
$m_O$        & Outer-motor multiplier    & [-2, 2] \\
\hline
$m_F$        & Front-motor multiplier    & [-1, 1] \\
\hline
$m_R$        & Right-motor multiplier    & [-1, 1] \\
\hline
\end{tabular}
\caption{The \emph{SineModel5} motion model parameters.}
\tablabel{parameters}
\label{tab:params}
\end{center}
\end{table}

\edit{called outer multiplier, but text says we multiply by inner. same for left}

Intuitively, SineModel5 starts with 8 identical sine waves of
amplitude $\amp$ and period $\tau$, multiplies the waves for all inner
motors by $m_O$, multiplies the waves for all front motors by $m_F$,
and multiplies the waves for all left motors by $m_R$.  To obtain the
actual motor position commands, these waves are offset by
appropriate fixed constants so that the base position (when the sine
waves are at 0) is approximately a crouch (the position shown in
\figref{robot_close.jpg}).  In this motion model, the ninth
(center) motor is kept at a neutral position.  Thus, the commanded
position for all motors, as a vector function of time, is:

\[
\vec{g}(t) =
\left[ {\begin{array}{c@{ }l@{ }l}
\amp \cdot \sin(2\pi t / \tau) & \ \cdot \           m_F            & + C_I \\ % 0
\amp \cdot \sin(2\pi t / \tau) & \ \cdot \ m_O \cdot m_F            & + C_O \\ % 1
\amp \cdot \sin(2\pi t / \tau) & \                                  & + C_I \\ % 2
\amp \cdot \sin(2\pi t / \tau) & \ \cdot \ m_O                      & + C_O \\ % 3
\amp \cdot \sin(2\pi t / \tau) & \ \cdot \                     m_R  & + C_I \\ % 4
\amp \cdot \sin(2\pi t / \tau) & \ \cdot \ m_O           \cdot m_R  & + C_O \\ % 5
\amp \cdot \sin(2\pi t / \tau) & \ \cdot \           m_F \cdot m_R  & + C_I \\ % 6
\amp \cdot \sin(2\pi t / \tau) & \ \cdot \ m_O \cdot m_F \cdot m_R  & + C_O \\ % 7
0                              & \                                  & + C_C \\ % 8
\end{array} } \right]
\]

\noindent Here the fixed constants that determine the crouched
position are $C_I = 800$ for inner motors, $C_O = 40$ for outer
motors, and $C_C = 512$ for the center hip motor.  The nine functions
correspond to the nine motors in the same order as listed in
\figref{topdown.png}.

\edit{what subscripts?}



\subsection{Learning Methods for Parametrized Motion Models}
\seclabel{learningMethods}

Using the SineModel5 parametrized motion model described in the
previous section, along with the allowable ranges for each of the five
parameters (shown in \tabref{parameters}), the task becomes how to
choose the combination of five parameters that results in the fastest
motion, per the evaluation methods in \secref{fitnessEvaluation}.

If we choose a value for the five dimensional parameter
$\vec{\theta}$, then a given physical trial gives us one measurement
of the fitness $f(\vec{\theta})$ of that parameter vector.  Two
things make learning difficult.  First, each evaluation of
$f(\vec{\theta})$ is expensive, taking 15-20 seconds on
average.  Second, the fitness returned by such evaluations has proved
to be very noisy, with the standard deviation of the noise often being
roughly equivalent to the size of the measurement.

We test the ability of different \emph{learning algorithms} to choose the next value of $\vec{\theta}$ to try, given a list of the
$\vec{\theta}$ values already evaluated and their fitness measurements $f(\vec{\theta})$.

We evaluated a total of seven different
learning algorithms for the parametrized motion models.  All methods
needed a way of picking a $\vec{\theta}$ for the first trial of each run.  This could be done by selecting a random starting vector within the
allowable domain.  However, to most directly compare learning methods
by their ability to improve on the initially chosen $\vec{\theta}$, we
decided to evaluate the different methods by starting them at the same three
initial $\vec{\theta}$ vectors in the three runs. 

%All employed a simple random sampling method for
%requirement (1); that is, all methods picked their initial
%$\vec{\theta}$ value via uniform random sampling within the allowed
%parameter ranges. \edit{make sure this is true. Isn't really, should say that we started with A, B, C}.  Thus, the
%differences in the algorithms was how they selected new $\vec{\theta}$
%values to try from their past experience.

The seven learning algorithms for the parametrized motion models are as follows:



%\section{Method}
%\seclabel{method}

% Describe in reasonable detail the algorithm you are using to address
% this problem. A pseudo-code description of the algorithm you are
% using is frequently useful. If it makes sense for your project,
% trace through a concrete example, showing how your algorithm
% processes this example. The example should be complex enough to
% illustrate all of the important aspects of the problem but simple
% enough to be easily understood. If possible, an intuitively
% meaningful example is better than one with meaningless symbols.

%We use several parametrized motion models that command motors to
%positions based on a sine wave, creating a periodic pattern.  While we
%investigated several models, for the bulk of our experiments, we used
%a model whose five parameters are: amplitude, wavelength, scale inner
%vs outer motors, scale left vs right motors, scale back vs front
%motors. Each strategy below attempts to choose the best possible
%parameters for this motion model.  

%We implemented and tested 8 different learning strategies.  All
%strategies except for the HyperNEAT method\cite{clune} were
%constrained to pick parameters from within predetermined ranges.

%\edit{JMC:Bullets=narrower column=wasted space. subsubsection instead?}

\begin{itemize}

\item \emph{Random}: This method randomly generates parameter vectors

  in the allowable range for every trial.  This strategy was used only
  as baseline for comparison.

\item \emph{Uniform random hill climbing}: This method always starts
  with the current best gait, and then chooses next $\vec{\theta}$ by
  randomly choosing one parameter to adjust and replacing it with a
  new value chosen with uniform probability in the allowable range for
  that parameter. This new point is evaluated, and if it results in a
  longer distance walked than the previous best gait, it is saved as
  the new best gait. The process is then repeated, always starting
  with the best gait.

\item \emph{Gaussian random hill climbing}: This method works
  similarly to Uniform random hill climbing, except the next
  $\vec{\theta}$ is generated by adding random Gaussian noise to the
  current best gait.  This results in all parameters being changed at
  once, but the resulting vector is always fairly close to the
  previous best gait.  We used independently selected noise in each
  dimension, scaled such that the standard deviation of the noise was
  5\% of the range of that dimension.

\item \emph{N-dimensional policy gradient ascent}: We implemented Kohl
  and Stone's \cite{kohl} method for local gradient ascent for gait
  learning with noisy fitness evaluations. This strategy explicitly
  estimates the gradient of the objective function. It does this by
  first generating $n$ parameter vectors near the initial vector by
  perturbing each dimension of each vector randomly by either
  $-\epsilon$, $0$, or $\epsilon$. Then each vector is run on the
  robot, and for each dimension we group the results into three
  groups: $-\epsilon$, $0$, and $\epsilon$.  The gradient along this
  dimension is then estimated as the average score for the $\epsilon$
  group minus the average score for the $-\epsilon$ group. Finally,
  the method creates the next $\vec{\theta}$ by changing all
  parameters by a fixed-size step in the direction of the gradient.
  For this study we used values of $\epsilon$ equal to 5\% of the
  allowable range in each dimension (ranges listed in
  \tabref{parameters}), and a step size scaled such that if all dimensions
  were in the range [0,~1], the norm of the step size would be 0.1.

\item \emph{Nelder-Mead simplex method}: The Nelder-Mead simplex
  method \cite{nm} creates an initial simplex with $d+1$ vertices,
  where $d$ is the dimension of the parameter space. The initial
  parameter vector is stored as the first vertex and the other five
  vertices are created by adding to one dimension at a time one tenth
  of the allowable range for that parameter. It then tests the fitness
  of each vertex, and, in general, it reflects the worst point over
  the centroid in an attempt to improve it.  However, to prevent
  cycles and becoming stuck in local minima, several other rules are
  used.  If the reflected point is better than the second worst point
  and worse than the best point, then the reflected point replaces the
  worst. If the reflected point is better than the best point, the
  simplex is expanded in the direction of the reflected point. The
  better of the reflected and the expanded point replaces the worst
  point. If the reflected point is worse than the second worst point,
  then the simplex is contracted away from the reflected point. If the
  contracted point is better than the reflected point, the contracted
  point replaces the worst point. If the contracted point is worse
  than the reflected point, the entire simplex is shrunk \cite{nm}.

\item \emph{Linear regression}: To initialize, this method chooses and
  evaluates five random parameter vectors. It then fits a linear model
  from parameter vector to fitness. In a loop, the method chooses and
  evaluates a new parameter vector generated by taking a fixed-size
  step in the direction of the gradient for each parameter, and fits a
  new linear model to all vectors evaluated so far, choosing the model
  to minimize the sum of squared errors. The step size is the same as in
  \emph{N-dimensional policy gradient ascent}.

%\item \emph{SVM regression}: Similarly to linear regression, this
%  model starts with several random vectors, but this time they are
%  chosen in a small neighborhood about some initial random vector.
%  These vectors (generally 8) are evaluated, and a support vector
%  regression model is fit to the observed fitnesses.  To choose the
%  next vector for evaluation, we randomly generate 100 vectors in the
%  neighborhood of the best observed gait, and select for evaluation
%  the vector with the best predicted performance in the learned model.
%  We suspected that if we always chose the best predicted point out of
%  100, we may end up progressing along a narrow subspace, prohibiting
%  learning of the true local fitness function.  Put another way, we
%  would always choose exploitation of knowledge vs. exploration of the
%  space.  To address this concern, we added a small amount of noise to
%  the new chosen $\vec{\theta}$ before continuing with the next phase
%  of evaluation and modeling.
%
%  Such a method naturally has many tunable parameters, and we
%  endeavored to select these parameters by tuning the method in
%  simulation.  To estimate the performance of the algorithm, we ran it
%  against a simulation with a known optimum.  The simulated function
%  was in the same five dimensional parameter space, and simply
%  returned a fitness determined as the height of a Gaussian with a
%  random mean.  The width of the Gaussian in each dimension was 20\%
%  of the range of each dimension, and the maximum value at the peak
%  was 100.  \figref{svm_sim_results} shows the learning results on
%  this simulated model using the ultimately selected SVM parameters.
%  Interestingly, a non-zero value of \code{bumpBy} resulted in better
%  learning than noise free (exploration free) learning.
%
%  \edit{JMC: This next paragraph sounds like it belongs in Results?}
%  Ultimately, however, the version of SVM tuned for simulation still
%  did not show competitive performance on the real robot.  We tried
%  tuning some parameters on the real robot, but after some amount of
%  tuning, the method still exhibited too little exploration and easily
%  became stuck in local minima.




\end{itemize}

