\section{Methods}

\subsection{Policy Representation by Splines}
The simplest model with back-compatibility is geometric
splines. For example, for a given model f(x) with K knots, we can preserve the
exact shape of the generated curve while adding extra knots to the
original spline. If we put one additional knot between every two
consecutive knots of the original spline, we end up with a 2K - 1
knots and a spline that has the same shape as the original one. In
order to do this, we need to define an algorithm for evolving the
parameterization from $K$ to $L$ knots ($L > K$), which is formulated as in
\ref{alg_Evolve_Spline}.  Without loss of generality, the policy parameters are
normalized into $[0, 1]$, and appropriately scaled and shifted as necessary upon use.

\begin{algorithm}
\caption{EvolvePolicy-Spline ($P_{current}$: current policy, $L$: desired new number of parameters)}
\label{alg_Evolve_Spline}
\begin{algorithmic}[1]

\STATE $K$ $\leftarrow$ $P_{current}.numberOfParameters$

\STATE $X_{current}$ $\leftarrow$ $[0, \frac{1}{K-1}, \frac{2}{K-1}, ... , 1]$ % Knots
\STATE $Y_{current}$ $\leftarrow$ $P_{current}.parameterValues$ % Values
\STATE $S_{current}$ $\leftarrow$ ConstructSpline($X_{current}$, $Y_{current}$) % Spline
%\COMMENT{ Optional: make the spline cyclic}

\STATE $X_{new}$ $\leftarrow$ $[0, \frac{1}{L-1}, \frac{2}{L-1}, ... , 1]$
\STATE $Y_{new}$ $\leftarrow$ EvaluateSplineAtKnots($S_{current}$, $X_{new}$)
\STATE $S_{new}$ $\leftarrow$ ConstructSpline($X_{new}$, $Y_{new}$)
%\COMMENT{ Optional: make the spline cyclic}

\STATE $P_{new}.numberOfParameters$ $\leftarrow$ $L$
\STATE $P_{new}.parameterValues$ $\leftarrow$ $S_{new}$.$Y_{new}$

\STATE return $P_{new}$

\end{algorithmic}
\end{algorithm}



\subsection{Parameterized Gaits by RL PoWER}

Here we used an RL approach to change the complexity of the policy
representation dynamically while the trial is running. In
earlier studies on reducing energy
consumption for bipedal robots \citep{kormushev2011bipedal-walking-energy}, a mechanism that can
evolve the policy parameterization was used. The method starts from a
very simple parameterization and gradually increases its
representational capability. The method was tested to be capable of generating
an adaptive policy parameterization that can accommodate increasingly
more complex policies. Presented in the studies of \cite{kormushev2011bipedal-walking-energy}, the policy
generated by this approach can reach the global optimum at a fast
rate when applied to the energy reduction problem. Another property found about this method is its chance of converging to a suboptimal solution is reduced, because in the lower-dimensional representation this effect is less exhibited.

\figp{powerSplinesExample}{.6}{An example for an evolving policy parameterization based on
spline representation of the policy. The set of spline knots is the policy
parameterization. The spline knots are the actual policy parameter
values. This original parameterization starts from 4 knots and grows up to 32 knots}

\cite{kober2009learning-motor-primitives} proposed a RL algorithm
named Policy learning by Weighting Exploration with the
Returns (RL PoWER), which is based on Expectation-Maximization algorithm
(EM). The reason for using this is its relatively fewer parameters that need tuning. We
evolved the policy parameterization only on those past trials ranked
the highest by the importance sampling technique used by the PoWER
algorithm. The intuition behind is that highly ranked
parameterizations have more potential to evolve even better in the
future. Besides, evolving all the parameterizations increases the exploring space. Since our experiment
is done on a physical robot, exploring all the variations of every
parameterization is not practical. Future work may incorporate simulations into the studies, as illustrated in \cite{bongard2006resilient-machines-through}.

For the experiment, we set the splines to have 3 knots for each servo, and there are 8
servos in total. The servo in the hip is not used in
our experiment. Previous work has verified that quadruped gaits
perform better when they are coordinated \citep{clune2009evolving-coordinated-quadruped, clune2011on-the-performance-of-indirect-encoding, valsalam2008modular-neuroevolution-for-multilegged}. For each spline, we calculate its corresponding parameterized gait for one unit time cycle of 1.8 seconds and then apply the same
pattern to every cycle throughout the 12 seconds of one
trial. Specifically, each spline (a set of 3 knots) is interpreted to its corresponding servo positions as in the following equation and in \tabref{params}.

\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Parameters        &                           &       \\
in $\vec{\theta}$ & Description               & Range \\
\hline
\hline
$f(s1,s2,s3)$        & Spline function           & [0,1] \\  %subject to change
\hline
$R$          & Position multiplier                & [256, 768] \\
\hline
\end{tabular}
\caption{The \emph{RL PoWER} motion model parameters.}
\tablabel{parameters}
\tablabel{params}
\end{center}
\end{table}


\[
\vec{g}(t) =
\left[ {\begin{array}{c@{ }c@{ }c@{ }l@{ }l}
R \cdot f(s1, s2, s3) & \ \          & \             & \            & + C \\ % 1
0                              & \             & \             & \            & + C_C \\ % 8
\end{array} } \right]
\]
