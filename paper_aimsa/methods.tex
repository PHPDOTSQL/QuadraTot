\section{Methods}

\subsection{Policy Representation by Splines}
The simplest model with back-compatibility is geometric
splines. For a given model f(x) with K knots, we can preserve the
exact shape of the generated curve while adding extra knots to the
original spline. Say, if we put one additional knot between every two
consecutive knots of the original spline, we end up with a 2K - 1
knots and a spline that has the same shape as the original one. In
order to do this, we need to define an algorithm for evolving the
parameterization from $K$ to $L$ knots ($L > K$), which is formulated as 
Algorithm 1 in \cite{kormushev2011bipedal-walking-energy}.  Without loss of generality, the policy parameters are
normalized into $[0, 1]$, and appropriately scaled/shifted as necessary
later upon use.

\subsection{Parameterized Gaits by RL PoWER}

Here we used an RL approach to change the complexity of the policy
representation dynamically while the trial is running. In
\cite{kormushev2011bipedal-walking-energy}'s studies on reducing energy
consumption for bipedal robots, a mechanism that can
evolve the policy parameterization was used. The method starts from a
very simple parameterization and gradually increases its
representational capability. The method was tested to be capable of generating
an adaptive policy parameterization that can accommodate increasingly
more complex policies. Presented in the studies of \cite{kormushev2011bipedal-walking-energy}, the policy
generated by this approach can reach the global optimum at a fast
rate when applied to the energy reduction problem. Another property found about this method is its chance of converging to a suboptimal solution is reduced, because in the lower-dimensional representation this effect is less exhibited.

\figp{powerSplinesExample}{.6}{An example for an evolving policy parameterization based on
spline representation of the policy. The set of spline knots is the policy
parameterization. The spline knots are the actual policy parameter
values. This original parameterization starts from 4 knots and grows up to 32 knots}

\cite{kober2009learning-motor-primitives} proposed a RL algorithm
called Policy learning by Weighting Exploration with the
Returns(PoWER), which is based on Expectation-Maximization algorithm
(EM). The proposed technique for evolving the policy parameterization
is a combination with this EM-based RL algorithm, named PoWER \cite{kober2009learning-motor-primitives}. The reason for using this is its relatively fewer parameters that need tuning. We
evolved the policy parameterization only on those past trials ranked
the highest by the importance sampling technique used by the PoWER
algorithm. The intuition behind is that highly ranked
parameterizations have more potential to evolve even better in the
future. Besides, evolving all the parameterizations increases the exploring space. Since our experiment
is done on a physical robot, explore all the variations of every
parameterization is not practical. Future work may incorporate simulations into the studies, as illustrated in \cite{bongard2006resilient-machines-through}.

For the experiment, we set 3 knots for each servo and there are 8
servos in total. The servo in the hip is not used in
our experiment. Previous work has verified that quadruped gaits
perform better when they are coordinated \cite{clune2009evolving-coordinated-quadruped} \cite{clune2011on-the-performance-of-indirect-encoding}
\cite{valsalam2008modular-neuroevolution-for-multilegged}. For each spline, we calculate its corresponding parameterized gait for one unit time cycle. Given that, then apply the same
pattern to every cycle throughout the 12 seconds of one
trial. Specifically, each spline(a set of 3 knots) is interpreted to its corresponding servo positions as
following:

\begin{table}[b]
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Parameters        &                           &       \\
in $\vec{\theta}$ & Description               & Range \\
\hline
\hline
$f(s1,s2,s3)$        & Spline function           & [0,1] \\  %subject to change
\hline
$R$          & Position multiplier                & [256, 768] \\
\hline
\end{tabular}
\caption{The \emph{RL PoWER} motion model parameters.}
\tablabel{parameters}
\label{tab:params}
\end{center}
\end{table}


\[
\vec{g}(t) =
\left[ {\begin{array}{c@{ }c@{ }c@{ }l@{ }l}
R \cdot f(s1, s2, s3) & \ \          & \             & \            & + C \\ % 1
0                              & \             & \             & \            & + C_C \\ % 8
\end{array} } \right]
\]



