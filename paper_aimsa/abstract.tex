A reinforcement learning approach which can evolve the policy parameterization dynamically during
the learning process for quadruped robot gait \edit{???}. By gradually increasing the representational
power of the policy parameterization, it manages to find better
policies faster than HyperNEAT, a state-of-the-art evolutionary ANN algorithm that achieved the best performance in previous studies.

Expectation-Maximization-based reinforcement learning algorithm
is used. The test was done on a physical quadrupedal robot (QuadraTot). The results show that the evolving policy parameterization combined with expectation-maximization (RL PoWER)
outperforms substantially the HyperNEAT, by having
faster convergence and higher final
reward. According to the statistics collected, the RL PoWER achieves 16.3\%
advantage over the HyperNEAT, the best method tested on QuadraTot in previous studies.
