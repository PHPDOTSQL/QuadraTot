\section{Introduction}

\figp{quadratotWhiteBooties}{.75}{The quadratot robot used in this research. The white booties are newly added to prevent sliding on the surface thus minimize measure error.}

Various learning algorithms have been proved to be effective for
legged robots. Algorithms such as HyperNEAT \cite{yosinski2011evolving-robot-gaits},
GA \cite{chernova2004an-evolutionary-approach-to-gait} and others \cite{hornby2005autonomous-evolution-of-dynamic} \cite{zykov2004evolving-dynamic-gaits} \cite{tellez2006evolving-the-walking-behaviour} \cite{valsalam2008modular-neuroevolution-for-multilegged} have been tested to be effective for automatic learning gaits for robots. Despite of the competetive performance, a major
task that are usually hidden in the published results lies in tuning the parameters for
these evolutionary algorithms \cite{kormushev2011bipedal-walking-energya}. Here we present a
different way for learning gaits using reinforcement learning and expectation maximization, called RL PoWER. In our
experiment, the main focus of the research is on the applicability of RL PoWER to quadruped robot gait learning. Another motivation is to compare the state-of-the-art neural network algorithm, HyperNEAT, with our proposed method in quadruped robot gait learning.

\subsection{Problem Definition}
The gait learning problem is defined to find a
gait that maximizes some specific metric. Mathematically, we define a
gait as a function that specifies a vector of commanded motor
positions for a robot over time. Gaits without feedback---also
called open-loop gaits---can be defined as 

\be\vec{x} = g(t)\ee

According to this definition, open-loop gaits are deterministic. One
particular gait should behave exactly the same when it is run from
trial to trial. However, the actual robot motion and fitness measured
will vary due to the errors and uncertainty of the real world physics. In our
trials, the gaits generated were sent to the robot and
executed in an open loop manner. We will measure and analyze the performance between
RL PoWER and HyperNEAT, the latter of which will be the focus of discussion in this paper. The metric used for the fitness in this paper will be
described later.
