\section{Introduction}

\figp{quadratotWhiteBooties}{.75}{The open source, 3D printed
  QuadraTot robot used in this research. The white printed booties are
  new addition to prevent sliding on surfaces and to minimize measurement
  error.}

Various learning algorithms have been proved to be effective for
legged robots. Algorithms such as HyperNEAT
\citep{yosinski2011evolving-robot-gaits}, Genetic Algorithms
\citep{chernova2004an-evolutionary-approach-to-gait} and others
\citep{hornby2005autonomous-evolution-of-dynamic,
  zykov2004evolving-dynamic-gaits,
  tellez2006evolving-the-walking-behaviour,
  valsalam2008modular-neuroevolution-for-multilegged} have been tested
to be effective for automatic learning gaits for robots. Despite
competitive performance, a major task is usually hidden in the
published results: tuning the parameters for these evolutionary
algorithms \citep{kormushev2011bipedal-walking-energy}. Here we
present results using a different way of learning gaits: a
Reinforcement Learning algorithm called Policy learning by Weighting
Exploration with the Returns, or RL PoWER, proposed by
\cite{kober2009learning-motor-primitives}. In our experiment, the main
focus of the research is on the applicability of RL PoWER to quadruped
robot gait learning. Another motivation is to compare the
state-of-the-art neural network algorithm, HyperNEAT, with our
proposed method in quadruped robot gait learning.



\subsection{Problem Definition}

As in \cite{yosinski2011evolving-robot-gaits}, we define the gait learning problem to be the search for a
gait that maximizes some specific metric. Mathematically, we define a
gait as a function that specifies a vector of commanded motor
positions for a robot over time. Gaits without feedback---also
called open-loop gaits---can be defined as 

\be\vec{x} = g(t)\ee

According to this definition, open-loop gaits are deterministic. One
particular gait should behave exactly the same when it is run from
trial to trial. However, the actual robot motion and fitness measured
will vary due to the errors and uncertainty of the real world physics. In our
trials, the gaits generated were sent to the robot and
executed in an open loop manner. We will measure and analyze the performance between HyperNEAT and 
RL PoWER, the latter of which will be the focus of discussion in this paper. The metric used for the fitness in this paper will be
described later.
