\section{Introduction}
% Motivate and abstractly describe the problem you are addressing and
% how you are addressing it. What is the problem? Why is it important?
% What is your basic approach? A short discussion of how it fits into % related work in the area is also desirable. Summarize the basic results
% and conclusions that you will present.

This paper presents a comparison of varied learning methods to
design a gait for a quadruped robot. Using these methods we have
created walks that are several times faster than the original
hand-tuned gait. 

A video presentation of this project should be viewed at

http://www.youtube.com/watch?v=ODoiOj9DdGg.
\edit{write this}



\section{Problem definition}
% Precisely define the problem you are addressing (i.e. formally specify
% the inputs and outputs). Elaborate on why this is an interesting and
% important problem.
We are testing several different learning methods to design a parametrized 
gait for a quadruped robot from the Cornell Computational Synthesis Lab. 
The metric for evaluation of the designed gait is speed. Given parameters 
for the current walk and the current time, our code outputs the position
of each of the robot's motors. A comparison and evaluation 
of the many different methods available for optimizing the gait of legged 
robots will be useful for future work on this challenging multidimensional 
control problem.

\section{Method}
% Describe in reasonable detail the algorithm you are using to address this 
% problem. A pseudo-code description of the algorithm you are using is 
% frequently useful. If it makes sense for your project, trace through a 
% concrete example, showing how your algorithm processes this example. The 
% example should be complex enough to illustrate all of the important aspects 
% of the problem but simple enough to be easily understood. If possible, 
% an intuitively meaningful example is better than one with meaningless 
% symbols.

We have a parameterized motion model that commands motors to positions
based on a sine wave, creating a periodic pattern. Parameters are: 
amplitude, wavelength, scale inner vs outer motors, scale left vs right 
motors, scale back vs front motors. Each strategy below attempts to choose
the best possible parameters for this motion model. 

We implemented and tested 8 different learning strategies:
\begin{itemize}
\item \emph{Uniform random hill climbing}: Creates a random neighbor by
  randomly choosing one parameter to adjust, and changing it completely 
  randomly in UniformStrategy(). Then evaluates this neighbor by running 
  the robot with the newly chosen parameters. If this neighbor results in a
  longer distance walked then the previous best neighbor, we save this
  neighbor as the new best neighbor. We then repeat the whole process
  using the best neighbor as a base.
\item \emph{Gaussian random hill climbing}: Creates a random neighbor by
  changing each parameter randomly based on a normal distribution. Then
  evaluates this neighbor similarly to uniform random hill climbing.
\item \emph{N-dimensional policy gradient descent}: Estimates the policy
  gradient by evaluating \emph{t} randomly generated policies
  near an initial parameter vector. Then computes the average score for
  each parameter and adjusts the base policy according to the estimated
  gradient.
\item \emph{Random}: Randomly generates parameter vector in the allowable
  range. This strategy is used only as base line.
\item \emph{Simplex (Nelder-Mead) Method}: Creates a simplex with 6 vertices and tests the fitness of each vertex. The worst vertex is reflected over the centroid. If the reflected point is better than the second worst point and worse than the best point, then the reflected point replaces the worst. If the reflected point is better than the best point, the simplex is expanded in the direction of the reflected point. The better of the reflected and the expanded point replaces the worst point. If the reflected point is worse than the second worst point, then the simplex is contracted away from the reflected point. If the contracted point is better than the reflected point, the contracted point replaces the worst point. If the contracted point is worse than the reflected point, the entire simplex is shrunk \cite{NMWebsite}.
\item \emph{Linear regression}: To initialize, chooses five random points
and trains on them using least-squares. Then in a loop, takes a fixed-size
step in the direction of the gradient, and retrains on all points so far.
\item \emph{SVM regression}
\item \emph{Evolutionary Neural Network (HyperNEAT)\cite{2}}
\end{itemize}

\section{Related work}
% Briefly explain who else worked on related problems in the past and what
% methods they used. Explain if you are using similar methods, or if your
% approach is different and if so - how (either is ok).

Various maching learning techniques have proven to be useful in finding
control policies for a wide variety of robots. Kohl and Stone\cite{1}
presented a policy gradient reinforcement learning approach for generating
a fast walk on legged robots. We experimented with this method to create
a walk for our robot (Policy Gradient Descent). Chernova and Velosa\cite{3}
took an evolutionary approach to this problem which we did not implement.
Zykov, Bongard, and Lipson\cite{4} describe the evolution of dynamic gaits 
on a physical robot requiring no prior
assumptions about the locomotion pattern beyond the fact that it should be
rhythmic. 


\section{System Architecture and Implementation}
\seclabel{implement}
% Describe how you implemented your system and how you structured it. 
% This should give an overview of the system, not a detailed 
% documentation of the code. The documentation of the code is part of 
% the code you hand in. You might want to comment on high-level design 
% decisions that you made. Also explain how you obtained your
% data and any pre-processing you did to it.

The quadruped robot has an on-board computer running Linux. The lower
level drivers are in C and the system is implemented in Python. Feedback about distance travelled is provided via an infrared LED and a Wii remote. 

\begin{itemize}

\item \code{Robot} class: Class wrapper for commanding
  motion of the robot.  The \code{Robot} class takes care of the robot
  initialization, communication with the servos, and timing of the
  runs.  In addition, it prevents the servos from ever being commanded
  to a point outside their normal range (0 - 1023) as well as beyond
  points where limbs would collide with parts of the robot body.  The
  main class function, \code{run}, accepts a motion model (any
  function that takes a time argument and outputs a 9 dimensional
  position) and will run the robot using this motion model, including,
  if desired, smooth interpolation over time for the beginning and end
  of the run.

\item \code{RunManager} class: Deals with all the details of running the robot,
  including choosing an initial parameter, running the robot multiple times, 
  tracking distance walked, and writing to the log file. Also includes the
  \code{explore\_dimensions} method.

\item \code{Strategy} class: The user has a choice between seven
  different learning strategies: uniform random hill climbing, Gaussian random
  hill climbing, N-dimensional policy gradient descent, random, 
  simplex, linear regression/prediction, and SVM regression/prediction.

\item \code{MotionModel} abstract base class: Several functions exist,
  but none are within a class framework. ... ??? ...
  
  \begin{itemize} 
  \item \code{SineModel}
  classes: Commands motors to positions based on a sine wave, creating
  a periodic pattern. Parameters are: amplitude, wavelength, scale
  inner vs outer motors, scale left vs right motors, scale back vs
  front motors. Currently a function, not a class. ... ??? ... There
  are also other motion models... 

  \item Other derived motion model classes:
  Several versions of a SineModel exist, each with different
  parameters, though solely as functions.
  \end{itemize}

\item \code{WiiTrackClient} and \code{WiiTrackServer} classes and
  hardware: A Wii remote tracks the location of the robot through an
  infrared LED mounted on top of the robot. We used the CWiid library
  which is able to interface with the remote via bluetooth to
  determine the location of the infrared LED. This information is
  accessed through some functions we wrote and passed to the
  program. The program gets the robot's position at the beginning of
  each run and then again at the end. The program then calculates the
  net change in position and uses that as the distance
  walked. \edit{Jason: add details}.

\end{itemize}

\section{Experimental Evaluation}

\subsection{Methodology}
% What are the criteria you are using to evaluate your method? What
% specific hypotheses does your experiment test? Describe the 
% experimental methodology that you used. What are the dependent and 
% independent variables? For projects in machine learning, what is 
% the training/test data that was used, and why is it realistic or
% interesting? Exactly what performance data did you collect and how 
% are you presenting and analyzing it? Comparisons to competing methods 
% that address the same problem or to variations of your own algorithm 
% are particularly useful.

The metric for evaluation of the designed gait is speed. We stop each 
run after plateauing results (no improvement for one third of the 
policies seen so far). The standard length of a run designates that it
should be stopped after there is no improvement for one half of the policies
seen so far, but since all runs took place on the actual robot, without use
of a simulator, certain time limitations were imposed on the learning process.

We controlled our experiments from a computer that was connected via a 
wireless ethernet to the robot. The robot collected data about distance
walked automatically on its own. If it walked outside of the Wii remote's
viewable area, it informed the user, so the only human intervention
required during an experiment involved moving the robot back inside the 
viewable area and restarting it and dealing with various mechanical failures,
which did not interrupt the learning process or result in the loss of data.

We evaluated the efficacy of a set of parameters by sending these
parameters to the robot and instructing it to walk for a certain length
of time. The robot always begins from the same position and returns to the
starting position at the end of the run in order to allow for uniformity
in measuring. More efficient parameters resulted in a faster gait, which
translated into a longer distance walked and a better score. After completing
an evaluation, the robot sent the resulting distance walked back to the
host computer and prepared itself for a new set of parameters to evaluate.

Each algorithm was run on 3 different initial parameter vectors on the
physical robot. We decided to evaluate all methods starting at the
same three vector in order to allow for the fair comparison of each
algorithm.  We evaluate
each method based on the amount of improvement seen from the initial
parameter vectors, and on the fastest speeds achieved during runs.

The resulting gaits from our algorithms quickly outperformed the original
hand-coded walk designed for this robot. The fasted walk, for example, was
4 times faster.

\subsection{Results}
% Present the quantitative results of your experiments. Graphical data
% presentation such as graphs and histograms are frequently better 
% than tables. Explain what are the basic differences revealed in the 
% data. If your method is stochastic or you analyze multiple datasets, 
% calculate mean and standard error for every quantitative
% performance result you show based on multiple runs.

We have done runs of 
3 different initial parameter vectors for random hill climbing, 
Gaussian random hill climbing, policy gradient descent, random,
simplex, and linear regression. We developed several
gaits that were about 4 times faster than the original hand-coded gait. 

\editbox{Pull out vectors A, B, and C into separate bulletted list, and
  make table, like below}


\begin{tabular}{|r|c|c|c|}
\hline
                                         & A       & B      & C      \\
\hline
Uniform Random Hill Climbing             & 11.37   & 9.44   & 2.69   \\
\hline
Gaussian Random Hill Climbing            & 3.10    & 13.59  & 13.40  \\
\hline
Policy Gradient Descent                  & 0.68    & 14.69  & 3.60   \\
\hline
Random                                   & 6.04    & 17.26  & 4.90   \\
\hline
Simplex (Nelder-Mead)                    & 8.51    & 13.62  & 14.83  \\
\hline
Linear Regression                        & 27.58   & 12.51  & 1.95   \\
\hline
SVM Regression                           & ???     & ???    & ???    \\
\hline
Evolutionary Neural Network (HyperNEAT)  & ???     & ???    & ???    \\
\hline
\end{tabular}



\begin{itemize}

\item For vector A, linear regression worked significantly better than the other algorithms, resulting in a gait (27.58 body lengths/minute) that walked over twice as fast as the next best gait (uniform random hill climbing - 11.37 body lengths/minute).

\item Vector B resulted in similarly performing gaits with all the algorithms. Random produced the best gait (17.26 body lengths/minute) and uniform random hill climbing produced the worst (9.44 body lengths/minute). The remaining algorithms each produced a gait around 13 body lengths/minute.

\item For vector C, simplex and Gaussian random hill climbing each produced a gait that substantially outperformed the other algorithms. Simplex resulted in a gait of nearly 15 body lengths/minute  and Gaussian random hill climbing produced a gait of just over 13 body lengths/minute, whereas the other algorithms returned gaits of less than 5 body lengths/minute.

\end{itemize}

Based on the three trials, linear regression worked the best, followed by simplex. Gaussian random hill climbing performed about as well as random, but it is unclear whether Gaussian would continue to improve and become much better than random if allowed to run for more iterations. Uniform random hill climbing and policy gradient descent performed similarly.

We also coded \code{explore\_dimensions} to collect data for dimension
varying plots. We intend to do further explore this by running
\code{explore\_dimension} around a parameter that produces a medium-good gait.

\edit{fix captions in this section too!}

\figvarp{vectorA}{.65}{Vector A.... more here....}{}

\figvarp{vectorB}{.65}{Vector B.... more here....}{}

\figvarp{vectorC}{.65}{Vector C.... more here....}{}

\figvarp{std_error}{1}{Standard error....}{}


\edit{Jason: add SVM and HyperNEAT results here!}



\subsection{Discussion}
% Is your hypothesis supported? What conclusions do the results support
% about the strengths and weaknesses of your method compared to other 
% methods? How can the results be explained in terms of the underlying 
% properties of the algorithm and/or the data.

\edit{important points... talk about these more :)}

\begin{itemize}
\item  Since only three trials were tested with each algorithm and no algorithm consistently outperformed the others, there is a large standard error for each algorithm. For this reason, it is unclear if any algorithm is superior to another in this application. More trials with each algorithm would be necessary to reach a definitive ranking of the performance of the algorithms.

\item Each algorithm discovered at least one gait of over 10 body lengths/minute, including random. For this reason, we speculate that the motion model may be more critical than the learning algorithm.
\end{itemize}



\section{Future work}
% What are the major shortcomings of your current method? For each 
% shortcoming, propose additions or enhancements that would help overcome it.

There are several additions we would make to flesh out our project. First,
the error margins for our runs was quite large, so reducing them would lead
to more conclusive data. It would also be insightful to run our algorithms
on different motion models to get a better idea of how well different
algorithms perform overall, and not just for our current motion model. We
also intend to experiment more with evolutionary algorithms/HyperNEAT. 
Some parameter vectors resulted in the robot turning, as opposed to it
walking long distances. This could be an interesting learning goal in
future projects. To these ends, we propose the following additions
and enhancements:

\begin{itemize}
\item More runs and/or longer runs
\item Different motion representations
\item Evolutionary algorithms/HyperNEAT\cite{2}
\item Learning how to turn
\end{itemize}



\section{Conclusion}
% Briefly summarize the important results and conclusions presented in 
% the paper. What are the most important points illustrated by your 
% work? How will your results improve future research and applications 
% in the area?

\edit{make this more awesome}

Because the fastest learned walk was not
significantly faster than the fastest randomly generated walk, we
conjecture that the motion representation for the robot is more
integral to forward speed than the learning algorithm.



\section{Acknowledgments}
% List any people not on the team who helped you with your project: Your
% TA, other people you consulted with or had useful discussions (say in 
% a word or two what they did), people who proofread your report, and 
% any external code you used (libraries etc).
\begin{itemize}
\item Hod Lipson, Cornell Computational Synthesis Lab: adviser
\item Jim T\o rreson, University of Oslo: adviser
\item Juan Zagal, University of Chile: designed and printed robot and provided assistance
\item Jeff Clune, CCSL Red Couch: collaborated on HyperNEAT implementation/testing
\item Cooper Bills, Cornell University: assisted with Wii tracker development
\item Anshumali Srivastava, Cornell University: Teaching Assistant
\end{itemize}

\section{The Team}
% A table listing the names of the people who worked on the project, and who
% did what.
\begin{itemize}
\item Diana Hidalgo: 
\begin{itemize}
\item Simplex (Nelder-Mead)
\item \code{WiiTrackClient} and \code{WiiTrackServer} classes and hardware
\item Plotting and evaluating results
\end{itemize}
\item Sarah Nguyen
\begin{itemize}
\item Random
\item Uniform random hill climbing
\item Gaussian random hill climbing
\item N-dimensional policy gradient descent
\item Linear regression and prediction
\item \code{RunManager} and \code{Strategy} classes
\item Video editing
\end{itemize}
\item Jason Yosinski
\begin{itemize}
\item SVM regression and prediction
\item Evolutionary Neural Network (HyperNEAT)
\item \code{WiiTrackClient} and \code{WiiTrackServer} classes and hardware
\item \code{Robot}, \code{RunManager}, and \code{Strategy} classes
\item \code{Parameterized Motion Model} abstract base class
\item \code{SineModel} classes
\item \code{explore\_dimensions}
\item Plotting and evaluating results
\end{itemize}
\end{itemize}

\section{Appendix}
% Describe the code files you uploaded into CMS

A brief description of the code uploaded to the CMS follows:

\begin{itemize}
\item \code{optimize.py}: Determines a strategy to try and runs the robot
  with that strategy.
\item \code{RunManager.py}: Deals with all the details of running the robot,
  including choosing an initial parameter, running the robot multiple times, 
  tracking distance walked, and writing to the log file. Also includes the
  \code{explore\_dimensions} method.
\item \code{Strategy.py}: Contains all the different possible strategies, which
  will be passed as objects in \code{optimize.py}. 
\item \code{Robot.py}: Implements the \code{Robot} class, described in
  \secref{implement}.
\item \code{SineModel.py}: Implements a sine based motion model,
  described in \secref{implement}.
\item \code{Motion.py}: Motion helper functions.
\item \code{WiiTrackServer.py}: Broadcasts the position of the infrared LED.
\item \code{WiiTrackClient.py}: Connects to the WiiTrackServer to get the current position information.
\end{itemize}

% LocalWords:  vertices
