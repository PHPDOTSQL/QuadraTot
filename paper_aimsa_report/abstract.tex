A reinforcement learning approach is proposed
which can evolve the policy parameterization dynamically during
the learning process for quadruped robot gait learning. By gradually increasing the representational
power of the policy parameterization, it manages to find better
policies faster than by using HyperNEAT, a state-of-art evolutionary ANN algorithm that achieved the best performance in previous studies.

Expectation-Maximization-based reinforcement learning algorithm
is used. The results show that the evolving policy parameterization combined with expectation-maximization (RL PoWER)
outperforms substantially the HyperNEAT, by having
faster convergence and higher final
reward.
